{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayesAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmehta32/NaiveBayes/blob/main/NaiveBayesAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "f8wj0lvYe9qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YnPfxgmiXHLm"
      },
      "outputs": [],
      "source": [
        "inputPath = '/content/NB-train.txt'\n",
        "with open(inputPath, \"r\") as inp:\n",
        "  vals = []\n",
        "  l = []\n",
        "  s = ''\n",
        "  for i in inp:\n",
        "    for j in i:\n",
        "      if j != ',': \n",
        "        s+=j\n",
        "      l.append(s)\n",
        "    break\n",
        "  \n",
        "  l = l[-2]\n",
        "  \n",
        "  l1 = []\n",
        "  s= ''\n",
        "  for it,i in enumerate(l):\n",
        "    if it == len(l)-1:\n",
        "      if i not in l1:\n",
        "        l1.append(i)\n",
        "    \n",
        "    if i!= ' ':\n",
        "      s+=i\n",
        "      continue\n",
        "\n",
        "    l1.append(s)\n",
        "    s = ''\n",
        "while('' in l1) :\n",
        "    l1.remove('')\n",
        "while(' ' in l1) :\n",
        "    l1.remove(' ')\n",
        "# print(l1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grab elements from the text file"
      ],
      "metadata": {
        "id": "ofwvBN4MbbVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "with open(inputPath, \"r\") as inp:\n",
        "  for it,i in enumerate(inp):\n",
        "    if it == 0:\n",
        "      continue\n",
        "    l.append(i[:-1])\n",
        "  mat = [n.split(', ') for n in l]\n",
        "\n",
        "  for i in range(len(mat)):\n",
        "    for j in range(len(mat[0])):\n",
        "      mat[i][j]=mat[i][j].strip()\n",
        "  mat1 = []\n",
        "  t= []\n"
      ],
      "metadata": {
        "id": "OfqQ_FnDbazd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data tabular visualization"
      ],
      "metadata": {
        "id": "KCaHRCzAOcxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(mat)\n",
        "df.columns =l1\n",
        "df['C'] = df['C'].str.replace(\" \", \"\")\n",
        "\n",
        "iv = []\n",
        "for i in df:\n",
        "  if i != 'C':\n",
        "    iv = np.append(iv,df[i].unique()) \n",
        "iv = np.unique(iv)\n"
      ],
      "metadata": {
        "id": "mOuntb4Zaw_c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive bayes implementation"
      ],
      "metadata": {
        "id": "82wA4wIrObrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = {}\n",
        "## P(c)\n",
        "tot = df['C'].count()\n",
        "a = df[df['C'] == '0'].count()[0]\n",
        "b = df[df['C'] == '1'].count()[0]\n",
        "## priori probabilites\n",
        "P0 = a/tot\n",
        "P1 = b/tot\n",
        "prob['P0'] = P0\n",
        "prob['P1'] = P1\n",
        "prior = df.groupby('C').size().div(tot)\n",
        "# print(prior)\n",
        "classes = prior.keys()\n",
        "classes = classes[1:]\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "ALrbgu0nOilk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02117c2f-dde4-4da8-d849-c252a912c17f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['N', 'Y'], dtype='object', name='C')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## toggle smoothening"
      ],
      "metadata": {
        "id": "8oTO2TXqJ1sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = False\n",
        "\n",
        "#iv = np.append(iv,'h')"
      ],
      "metadata": {
        "id": "GW-J8InC4MNa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating probabilities without smothing\n",
        "from collections import UserDict\n",
        "\n",
        "if not sm:\n",
        "  likelihood = UserDict()\n",
        "  for i in df: \n",
        "    if i!= 'C':\n",
        "      likelihood[i] = df.groupby(['C', i]).size().div(tot).div(prior)\n",
        "  for i in likelihood:\n",
        "    for j in classes:\n",
        "      for k in iv: #to compare each variable that we have in the file\n",
        "        try:\n",
        "          likelihood[i][j][k]\n",
        "        except KeyError:\n",
        "          likelihood[i] = likelihood[i].append(pd.Series(data = 0,index = [(j, k)]))\n",
        "  for i in likelihood:\n",
        "    for j in classes:\n",
        "        try:\n",
        "          likelihood[i][j]['h']\n",
        "        except KeyError:\n",
        "          likelihood[i] = likelihood[i].append(pd.Series(data = 0,index = [(j, 'h')]))\n",
        "                  \n",
        "  with open('NB_ probabilities_no_smoothing.txt', 'w') as f:\n",
        "    for j in classes:\n",
        "      f.write(f'P(C={j}) = {prior[j]} \\n')\n",
        "    for i in likelihood:\n",
        "      for j in classes:\n",
        "        for k in iv:\n",
        "            f.write(f'P({i}= {k} | C={j}) = {likelihood[i][j][k]} \\n')\n",
        "        mini = likelihood[i][j]['h']\n",
        "        f.write(f'P({i}= h | C={j}) = {mini} \\n')"
      ],
      "metadata": {
        "id": "N98Ci9WzX1bB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Probabilites wih smothening\n",
        "if sm:\n",
        "  likelihood = UserDict()\n",
        "  for i in df: \n",
        "    if i!= 'C':\n",
        "      likelihood[i] = df.groupby(['C', i]).size().add(1).div(tot+len(iv)+1).div(prior)   \n",
        "  for i in likelihood:\n",
        "    for j in classes:\n",
        "      for k in iv: #to compare each variable that we have in the file\n",
        "        try:\n",
        "          likelihood[i][j][k]\n",
        "          # print(1)\n",
        "        except KeyError:\n",
        "          # print('error')\n",
        "          d = (prior[j]+1)/(tot+len(iv)+1)\n",
        "          likelihood[i] = likelihood[i].append(pd.Series(data = d, index = [(j, k)]))\n",
        "  for i in likelihood:\n",
        "    for j in classes:\n",
        "        try:\n",
        "          likelihood[i][j]['h']\n",
        "        except KeyError:\n",
        "          d = (prior[j]+1)/(tot+len(iv)+1)\n",
        "          likelihood[i] = likelihood[i].append(pd.Series(data = d,index = [(j, 'h')]))\n",
        "  with open('NB_ probabilities_smoothing.txt', 'w') as f:\n",
        "    for j in classes:\n",
        "      f.write(f'P(C={j}) = {prior[j]} \\n')\n",
        "    for i in likelihood:\n",
        "      for j in classes:\n",
        "        for k in iv:\n",
        "            f.write(f'P({i}= {k} | C={j}) = {likelihood[i][j][k]} \\n')\n",
        "        mini = likelihood[i][j]['h']\n",
        "        f.write(f'P({i}= h | C={j}) = {mini} \\n')"
      ],
      "metadata": {
        "id": "G2dgD4Uj01Cr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading New Input"
      ],
      "metadata": {
        "id": "NLq2rmmoei3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputPath2 = '/content/NB-test.txt'\n",
        "with open(inputPath2, \"r\") as inp:\n",
        "  for i in inp:\n",
        "    total = 0\n",
        "    for x in i:\n",
        "      if x != \",\" or x != ' ':\n",
        "        pass\n",
        "        \n",
        "      "
      ],
      "metadata": {
        "id": "A8Txlzgad0G9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the file and inputting it into the an array\n",
        "\n",
        "with open(inputPath2, \"r\") as inp:\n",
        "  vals = []\n",
        "  l = []\n",
        "  s = ''\n",
        "  for i in inp:\n",
        "    for j in i:\n",
        "      if j != ',': #skips the , in the text file\n",
        "        s+=j\n",
        "      l.append(s)\n",
        "    break\n",
        "  print(l)\n",
        "  l = l[-2]\n",
        "  l1 = []\n",
        "  s= ''\n",
        "  l1 = l.split(' ')\n",
        "#getting rid of the extra space in between the numbers\n",
        "\n",
        "while('' in l1) :\n",
        "    l1.remove('')\n",
        "while(' ' in l1) :\n",
        "    l1.remove(' ')\n",
        "print(l1)"
      ],
      "metadata": {
        "id": "m2VrGb-3e5CE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d50a34e-8e63-42d3-dce7-58870564fa75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'A1', 'A1', 'A1 ', 'A1 A', 'A1 A2', 'A1 A2', 'A1 A2 ', 'A1 A2 A', 'A1 A2 A3', 'A1 A2 A3', 'A1 A2 A3 ', 'A1 A2 A3 A', 'A1 A2 A3 A4', 'A1 A2 A3 A4\\n']\n",
            "['A1', 'A2', 'A3', 'A4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieving the probabilities we got\n",
        "l = []\n",
        "with open(inputPath2, \"r\") as inp:\n",
        "  for it,i in enumerate(inp):\n",
        "    if it == 0:\n",
        "      continue\n",
        "    l.append(i)\n",
        "  mat = [n.split(', ') for n in l]\n",
        "  for i in range(len(mat)):\n",
        "    for j in range(len(mat[0])):\n",
        "      mat[i][j]=mat[i][j].strip()\n",
        "  print(mat,l1,classes)"
      ],
      "metadata": {
        "id": "uMNgQIrNDUqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57009c1c-2f10-46e5-abc0-8848653b2804"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['y', 'f', 'f', 'h'], ['y', 'f', 't', 'g'], ['y', 't', 'f', 'g'], ['y', 't', 'f', 'f'], ['m', 'f', 'g', 'f'], ['m', 'f', 't', 'g'], ['m', 't', 't', 'f'], ['o', 'f', 't', 'e'], ['o', 'f', 't', 'e'], ['o', 't', 'f', 'f']] ['A1', 'A2', 'A3', 'A4'] Index(['N', 'Y'], dtype='object', name='C')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction using trained naive bayes model"
      ],
      "metadata": {
        "id": "LtbS2xIEYSEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the probabilities to see what if the class label is either a 1 or 0\n",
        "p_item = []\n",
        "p_mat = []\n",
        "p_temp = []\n",
        "liky = 1\n",
        "\n",
        "for k in range(len(mat)):\n",
        "  for j in ['Y', 'N']:\n",
        "    liky = prior[j]\n",
        "    for i in range(len(l1)):\n",
        "        liky *= likelihood[l1[i]][j][mat[k][i]]\n",
        "    p_item.append(liky)\n",
        "  p_mat.append(p_item)\n",
        "  p_item = []\n",
        "print(p_mat)\n",
        "classInst = []\n",
        "for i in p_mat:\n",
        "  classInst.append(i.index(max(i)))\n",
        "print(classInst)\n",
        "\n",
        "with open('NB_test_smoothing.txt', 'w') as f:\n",
        "  for i in classInst:\n",
        "    f.write(f'{i} \\n')"
      ],
      "metadata": {
        "id": "AbgScPu6DydH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8faf2798-1b62-442e-b91f-b045c0d8b5d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0, 0.0], [0.01768706528071198, 0.0], [0.010528015048042847, 0.002279851809632374], [0.0035093383493476162, 0.007979481333713309], [0.0, 0.0], [0.021224478336854376, 0.0], [0.010106894446121131, 0.0], [0.03183671750528156, 0.0], [0.03183671750528156, 0.0], [0.004211206019217139, 0.005984611000284984]]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    }
  ]
}